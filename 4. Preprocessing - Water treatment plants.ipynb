{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab544e24",
   "metadata": {},
   "source": [
    "# Preprocessing: Water treatment plants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339f6d8",
   "metadata": {},
   "source": [
    "**Objective**: Prepare data from the **MERKUR** dataset for use in machine learning algorithms.\n",
    "\n",
    "**Background**: The MERKUR project, based in the *Research Centre for Built Environment, Climate, Water Technology and Digitalisation* at VIA University College, collects and analyzes data from water treatment plants in Denmark. In short, the project aims to understand how water treatment plants are run, and the results are then ideally used to optimize the running of water treatment plants. However, the dataset is, as of now, relatively \"dirty\" in a machine learning context: There are many missing values, outliers, a mix of categorical and numeric data, etc.\n",
    "\n",
    "**Data Source**: The dataset has kindly been provided to us by Senior Associate Professor Loren Mark Ramsay. You can read more [here](https://en.via.dk/research/built-environment-climate-water-technology-and-digitalisation/water-treatment-and-distribution) and [here](https://www.ucviden.dk/en/projects/merkur-national-web-baseret-dataplatform-til-drikkevandsbehandlin).\n",
    "\n",
    "Note that we are only working with a subset of the full database. This subset is saved as an Excel file, `merkur.xlsx`.\n",
    "\n",
    "#### Overall Instructions\n",
    "1. Explore the dataset to understand the features and their distributions.\n",
    "2. Preprocess the data, handling any missing values, outliers, etc.\n",
    "\n",
    "Below some suggestions are given but the assignment is relatively \"free\".\n",
    "\n",
    "Best of luck with your analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7517fbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r\"merkur.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd441e7",
   "metadata": {},
   "source": [
    "### Suggestions\n",
    "\n",
    "-  Filter out (i.e. remove) any irrelevant columns (e.g. names, IDs, etc.)\n",
    "-  Several columns contain missing values (NaNs). Find out how large a percentage each column is missing. Perhaps some of them lack so much data that you should consider removing them?\n",
    "-  Scale numeric data.\n",
    "-  For the features you choose to keep, impute the missing values in an appropriate way - or perhaps you find it more appropriate to delete the rows?\n",
    "-  Several features (e.g., \"PrimaryTrigger\") are categorical. Use one-hot encoding to turn them into numeric data. Be careful with the feature \"Stages\" - perhaps one-hot encoding is not the best choice here?\n",
    "-  If you you choose to remove or replace outliers, do this now. If you choose to keep, move on.\n",
    "-  Create a correlation matrix and discuss - based on this, you might want to drop certain columns.\n",
    "-  Consider whether some features should be transformed (e.g. using log, square root etc.) and do this if found relevant.\n",
    "-  There are only about 80 rows in the data set. Discuss consequences of this in terms of machine learning - as well as potential solutions. \n",
    "-  Think about whether there are other steps you find appropriate at this point. If not, declare your data set clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ffd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Visualize missing values with a heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# 2. Visualize data types\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.dtypes.value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Data Types Distribution')\n",
    "plt.xlabel('Data Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 3. Display summary statistics\n",
    "summary_stats = df.describe(include='all')  # Include all types\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_stats)\n",
    "\n",
    "# 4. Plot histograms for numeric columns with dynamic layout\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calculate the number of rows and columns for the subplots\n",
    "num_cols = 3  # Number of columns for subplots\n",
    "num_rows = (len(numeric_cols) + num_cols - 1) // num_cols  # Ceiling division for rows\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 5))\n",
    "axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "# Plot histograms\n",
    "for ax, col in zip(axes, numeric_cols):\n",
    "    df[col].hist(bins=30, ax=ax)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(len(numeric_cols), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57791cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with more than 50% missing values:\n",
      "['WaterworksName', 'PrimaryTrigger', 'AerationType', 'GravityPressureMixed', 'Stages']\n",
      "\n",
      "Updated dataset saved, with columns having over 50% missing values removed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(\"cleaned_merkur.xlsx\")\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "missing_percentages = df.isna().mean() * 100\n",
    "\n",
    "# Identify columns where missing percentage is high (e.g., above 50%)\n",
    "high_missing_columns = missing_percentages[missing_percentages > 50].index.tolist()\n",
    "print(\"\\nColumns with more than 50% missing values:\")\n",
    "print(high_missing_columns)\n",
    "# Drop columns with more than 50% missing values\n",
    "df.drop(columns=high_missing_columns, inplace=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_excel(\"cleaned_merkur.xlsx\", index=False)\n",
    "print(\"\\nUpdated dataset saved, with columns having over 50% missing values removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6010f6b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/cleaned_merkur.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Reload the file\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/cleaned_merkur.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Identify numeric columns for scaling\u001b[39;00m\n\u001b[0;32m     10\u001b[0m numeric_columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/cleaned_merkur.xlsx'"
     ]
    }
   ],
   "source": [
    "# Re-import necessary libraries and reload the dataset to proceed with scaling\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reload the file\n",
    "\n",
    "df = pd.read_excel('cleaned_merkur.xlsx')\n",
    "\n",
    "# Identify numeric columns for scaling\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Initialize the scaler and apply it to the numeric columns\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Display the first few rows of the scaled data to confirm successful scaling\n",
    "df_scaled.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
